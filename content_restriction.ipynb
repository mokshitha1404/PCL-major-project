{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "dataset_path = \"Dataset/crop_part1\"\n",
    "output_path = \"organized_dataset\"\n",
    "\n",
    "# Create output directories\n",
    "below_18_path = os.path.join(output_path, \"below_18\")\n",
    "above_18_path = os.path.join(output_path, \"above_18\")\n",
    "os.makedirs(below_18_path, exist_ok=True)\n",
    "os.makedirs(above_18_path, exist_ok=True)\n",
    "\n",
    "# Organize images\n",
    "for file_name in os.listdir(dataset_path):\n",
    "    if file_name.endswith(\".jpg\"):\n",
    "        age = int(file_name.split(\"_\")[0])  # Extract age from filename\n",
    "        src_path = os.path.join(dataset_path, file_name)\n",
    "        \n",
    "        if age < 18:\n",
    "            dest_path = os.path.join(below_18_path, file_name)\n",
    "        else:\n",
    "            dest_path = os.path.join(above_18_path, file_name)\n",
    "        \n",
    "        shutil.copy(src_path, dest_path)\n",
    "\n",
    "print(\"Dataset organized into 'below_18' and 'above_18' folders!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1950884,
     "status": "ok",
     "timestamp": 1742382395266,
     "user": {
      "displayName": "Neeraj babu Thatiparthi",
      "userId": "08017573369382824618"
     },
     "user_tz": -330
    },
    "id": "jJVlC_bd8R3X",
    "outputId": "d7be567a-4ef7-4613-f7ad-b3b9602e51be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7824 images belonging to 2 classes.\n",
      "Found 1956 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 253ms/step - accuracy: 0.8512 - loss: 0.3541 - val_accuracy: 0.6820 - val_loss: 0.7227\n",
      "Epoch 2/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 231ms/step - accuracy: 0.8997 - loss: 0.2393 - val_accuracy: 0.6800 - val_loss: 0.7436\n",
      "Epoch 3/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 269ms/step - accuracy: 0.9084 - loss: 0.2288 - val_accuracy: 0.6984 - val_loss: 0.7454\n",
      "Epoch 4/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 225ms/step - accuracy: 0.9169 - loss: 0.2042 - val_accuracy: 0.7004 - val_loss: 0.6443\n",
      "Epoch 5/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 230ms/step - accuracy: 0.9192 - loss: 0.2157 - val_accuracy: 0.6958 - val_loss: 0.6623\n",
      "Epoch 6/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 265ms/step - accuracy: 0.9159 - loss: 0.2114 - val_accuracy: 0.6927 - val_loss: 0.6670\n",
      "Epoch 7/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 268ms/step - accuracy: 0.9222 - loss: 0.1949 - val_accuracy: 0.6871 - val_loss: 0.6637\n",
      "Epoch 8/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 228ms/step - accuracy: 0.9245 - loss: 0.1932 - val_accuracy: 0.7117 - val_loss: 0.6692\n",
      "Epoch 9/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 227ms/step - accuracy: 0.9219 - loss: 0.1910 - val_accuracy: 0.6866 - val_loss: 0.7094\n",
      "Epoch 10/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 231ms/step - accuracy: 0.9218 - loss: 0.1928 - val_accuracy: 0.7019 - val_loss: 0.6276\n",
      "Epoch 1/5\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 295ms/step - accuracy: 0.8037 - loss: 0.4284 - val_accuracy: 0.4080 - val_loss: 4.0966\n",
      "Epoch 2/5\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 256ms/step - accuracy: 0.9035 - loss: 0.2426 - val_accuracy: 0.4233 - val_loss: 3.2297\n",
      "Epoch 3/5\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 252ms/step - accuracy: 0.9051 - loss: 0.2402 - val_accuracy: 0.4816 - val_loss: 1.9698\n",
      "Epoch 4/5\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 255ms/step - accuracy: 0.9250 - loss: 0.1874 - val_accuracy: 0.5695 - val_loss: 1.2160\n",
      "Epoch 5/5\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 293ms/step - accuracy: 0.9381 - loss: 0.1665 - val_accuracy: 0.7086 - val_loss: 0.6568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dataset_path = \"organized_dataset\"\n",
    "\n",
    "#  Define ImageDataGenerator for dynamic image loading\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize images\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 80% training, 20% validation\n",
    ")\n",
    "\n",
    "#  Create training and validation generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,  # Reduced batch size to avoid crashes\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "#  Load Pretrained MobileNetV2 Model \n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base model layers\n",
    "\n",
    "#  Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "#  Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#  Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "#  Fine-tune the base model for better accuracy (optional)\n",
    "base_model.trainable = True  # Unfreeze base model for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,  # Fine-tune for additional 5 epochs\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "#  Save the trained model\n",
    "model.save(\"age_classification_model.h5\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4480,
     "status": "ok",
     "timestamp": 1742382405157,
     "user": {
      "displayName": "Neeraj babu Thatiparthi",
      "userId": "08017573369382824618"
     },
     "user_tz": -330
    },
    "id": "arA8J5gP-tsz",
    "outputId": "59dacc9f-35c8-4b4b-a442-3e8c7c2b94ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812ms/step\n",
      "Predicted Age Category: Below 18\n",
      "⚠ Access Restricted: Some content is blocked for users under 18.\n",
      "Blocked websites: ['example18plus.com', 'adultsite.com']\n",
      "Restricted files: ['restricted_movie.mp4', 'explicit_content.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#  Load the trained age detection model\n",
    "model = load_model(\"age_classification_model.h5\")\n",
    "\n",
    "#  Function to predict age category\n",
    "def predict_age(image_path, model):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224))  # Resize to match model input\n",
    "    img = img / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    prediction = model.predict(img)[0][0]\n",
    "    return \"Above 18\" if prediction > 0.5 else \"Below 18\"\n",
    "\n",
    "#  Function to restrict content\n",
    "def restrict_content(age_category):\n",
    "    if age_category == \"Below 18\":\n",
    "        print(\"⚠ Access Restricted: Some content is blocked for users under 18.\")\n",
    "        # Example: Block access to specific websites\n",
    "        blocked_websites = [\"example18plus.com\", \"adultsite.com\"]\n",
    "        print(\"Blocked websites:\", blocked_websites)\n",
    "\n",
    "        # Example: Restrict access to specific files or videos\n",
    "        restricted_files = [\"restricted_movie.mp4\", \"explicit_content.pdf\"]\n",
    "        print(\"Restricted files:\", restricted_files)\n",
    "    else:\n",
    "        print(\"Full Access: No restrictions.\")\n",
    "\n",
    "#  Test with a new image\n",
    "test_image_path = \"example.webp\" # test image\n",
    "age_category = predict_age(test_image_path, model)\n",
    "print(f\"Predicted Age Category: {age_category}\")\n",
    "\n",
    "# Apply content restriction\n",
    "restrict_content(age_category)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMedtmnQQzR9qCW2aOD/DuC",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "content_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
